# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18TQPbEM5kVAQbkfSm95U3IjbaEOtsUlm
"""

from pydoc import doc
import spacy
import nltk
nltk.download ('punkt')

from spacy.lang.en.stop_words import STOP_WORDS
from spacy.lang.hi import STOP_WORDS as STOP_WORDS_HI
from string import punctuation
from heapq import nlargest

text = """A week ago a friend invited a couple of other couples over for dinner. Eventually, the food (but not the wine) was cleared off the table for what turned out to be some fierce Scrabbling. Heeding the strategy of going for the shorter, more valuable word over the longer cheaper word, our final play was “Bon,” which–as luck would have it!–happens to be a Japanese Buddhist festival, and not, as I had originally asserted while laying the tiles on the board, one half of a chocolate-covered cherry treat. Anyway, the strategy worked. My team only lost by 53 points instead of 58.

Just the day before, our host had written of the challenges of writing short. In journalism–my friend’s chosen trade, and mostly my own, too–Mark Twain’s observation undoubtedly applies: “I didn’t have time to write a short letter, so I wrote a long one instead.” The principle holds across genres, in letters, reporting, and other writing. It’s harder to be concise than to blather. (Full disclosure, this blog post will clock in at a blather-esque 803 words.) Good writing is boiled down, not baked full of air like a souffl??. No matter how yummy souffl??s may be. Which they are. Yummy like a Grisham novel.

Lately, I’ve been noticing how my sentences have a tendency to keep going when I write them onscreen. This goes for concentrated writing as well as correspondence. (Twain probably believed that correspondence, in an ideal world, also demands concentration. But he never used email.) Last week I caught myself packing four conjunctions into a three-line sentence in an email. That’s inexcusable. Since then, I have tried to eschew conjunctions whenever possible. Gone are the commas, the and’s, but’s, and so’s; in are staccato declaratives. Better to read like bad Hemingway than bad Faulkner."""

texthi = """भारत–भूमि
की महानता उसकी विशाल जनसंख्या अथवा भू–क्षेत्र के कारण नहीं, अपितु उसकी भव्य और अनुकरणीय उदार परम्पराओं के कारण रही है। आचार, विचार, चिन्तन, भाषा और वेशभूषा की विविधताओं को राष्ट्रीयता के सूत्र में पिरोकर भारत ने मानवीय एकता का आदर्श उपस्थित किया है।

धर्म के तत्व–
भारतीय मान्यता के अनुसार धैर्य, क्षमा, आत्मसंयम, चोरी न करना, पवित्र भावना, इन्द्रियों पर नियन्त्रण बुद्धिमत्ता, विद्या, सत्य और क्रोध न करना ये धर्म के दस लक्षण हैं।

सभी धर्म इनको अपना आदर्श और अपना अंग मानते हैं। महाभारत में कहा गया है कि जो सब धर्मों को सम्मान नहीं देता, वह धर्म नहीं अधर्म है। मनुष्य को मनुष्य का गला काटने की दुष्प्रेरणा, दूसरों का घर जलाने की और नारियों के अपमान की कु–शिक्षा अधर्म है और ईश्वर का घोर अपमान है।

"""

def summarizer(rawdocs):
  stopwords = list(STOP_WORDS)

  nlp = spacy.load('en_core_web_sm')

  doc = nlp(rawdocs)

  tokens = [token.text for token in doc]

  word_freq={}
  for word in doc:
    if word.text.lower() not in stopwords and word.text.lower() not in punctuation:
      if word.text not in word_freq.keys():
        word_freq[word.text]=1
      else:
        word_freq[word.text]+=1

  max_freq = max(word_freq.values())

  for word in word_freq.keys():
    word_freq[word] = word_freq[word]/max_freq

  sent_tokens = [sent for sent in doc.sents]

  sent_scores={}
  for sent in sent_tokens:
    for word in sent:
      if word.text in word_freq.keys():
        if sent not in sent_scores.keys():
          sent_scores[sent] = word_freq[word.text]
        else:
          sent_scores[sent] += word_freq[word.text]

  select_len = int(len(sent_tokens)*0.3)

  summary = nlargest(select_len, sent_scores, key=sent_scores.get)

  final_summary = [word.text for word in summary]
  summary = ' '.join(final_summary)

  # print(text)
  # print(summary)
  # print("Length of Original Text", len(text.split(' ')))
  # print("Length of Summarized Text", len(summary.split(' ')))

  return summary,doc,len(rawdocs.split(' ')),len(summary.split(' '))

def summarizerhi(rawdocshi):

  stopwordshi = list(STOP_WORDS_HI)

  dochi = nlp(texthi)

  tokenshi = [token.text for token in dochi]

  word_freqhi={}
  for word in dochi:
    if word.text.lower() not in stopwordshi and word.text.lower() not in punctuation:
      if word.text not in word_freqhi.keys():
        word_freqhi[word.text]=1
      else:
        word_freqhi[word.text]+=1

  max_freqhi = max(word_freqhi.values())

  for word in word_freqhi.keys():
    word_freqhi[word] = word_freqhi[word]/max_freqhi

  sent_tokenshi = [sent for sent in dochi.sents]

  sent_scoreshi={}
  for sent in sent_tokenshi:
    for word in sent:
      if word.text in word_freqhi.keys():
        if sent not in sent_scoreshi.keys():
          sent_scoreshi[sent] = word_freqhi[word.text]
      else:
        sent_scoreshi[sent] += word_freqhi[word.text]

  select_lenhi = int(len(sent_tokenshi)*0.3)

  summaryhi = nlargest(select_lenhi, sent_scoreshi, key=sent_scoreshi.get)

  final_summaryhi = [word.text for word in summaryhi]
  summaryhi = ' '.join(final_summaryhi)

  return summaryhi,dochi,len(rawdocshi.split(' ')),len(summaryhi.split(' '))
 


# texthi = """भारत–भूमि
# की महानता उसकी विशाल जनसंख्या अथवा भू–क्षेत्र के कारण नहीं, अपितु उसकी भव्य और अनुकरणीय उदार परम्पराओं के कारण रही है। आचार, विचार, चिन्तन, भाषा और वेशभूषा की विविधताओं को राष्ट्रीयता के सूत्र में पिरोकर भारत ने मानवीय एकता का आदर्श उपस्थित किया है।

# धर्म के तत्व–
# भारतीय मान्यता के अनुसार धैर्य, क्षमा, आत्मसंयम, चोरी न करना, पवित्र भावना, इन्द्रियों पर नियन्त्रण बुद्धिमत्ता, विद्या, सत्य और क्रोध न करना ये धर्म के दस लक्षण हैं।

# सभी धर्म इनको अपना आदर्श और अपना अंग मानते हैं। महाभारत में कहा गया है कि जो सब धर्मों को सम्मान नहीं देता, वह धर्म नहीं अधर्म है। मनुष्य को मनुष्य का गला काटने की दुष्प्रेरणा, दूसरों का घर जलाने की और नारियों के अपमान की कु–शिक्षा अधर्म है और ईश्वर का घोर अपमान है।

# """
# def summarizerhi(rawdocshi):

#   stopwordshi = list(STOP_WORDS_HI)

#   dochi = nlp(texthi)

#   tokenshi = [token.text for token in dochi]

#   word_freqhi={}
#   for word in dochi:
#     if word.text.lower() not in stopwordshi and word.text.lower() not in punctuation:
#       if word.text not in word_freqhi.keys():
#         word_freqhi[word.text]=1
#       else:
#         word_freqhi[word.text]+=1

#   max_freqhi = max(word_freqhi.values())

#   for word in word_freqhi.keys():
#     word_freqhi[word] = word_freqhi[word]/max_freqhi

#   sent_tokenshi = [sent for sent in dochi.sents]

#   sent_scoreshi={}
#   for sent in sent_tokenshi:
#     for word in sent:
#       if word.text in word_freqhi.keys():
#         if sent not in sent_scoreshi.keys():
#           sent_scoreshi[sent] = word_freqhi[word.text]
#       else:
#         sent_scoreshi[sent] += word_freqhi[word.text]

#   select_lenhi = int(len(sent_tokenshi)*0.3)

#   summaryhi = nlargest(select_lenhi, sent_scoreshi, key=sent_scoreshi.get)

#   final_summaryhi = [word.text for word in summaryhi]
#   summaryhi = ' '.join(final_summaryhi)

#   print(texthi)
#   print(summaryhi)
#   print("Length of Original Text", len(texthi.split(' ')))
#   print("Length of Summarized Text", len(summaryhi.split(' ')))
#   return summaryhi,dochi,len(rawdocshi.split(' ')),len(summaryhi.split(' '))